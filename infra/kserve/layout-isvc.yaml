# Layout InferenceService â€” custom predictor image
# Build image inside Minikube: eval $(minikube docker-env) && docker build -f apps/layout/Dockerfile -t layout:dev .
# Apply: kubectl apply -f infra/kserve/layout-isvc.yaml -n ocr-dev
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: layout
  namespace: ocr-dev
spec:
  predictor:
    minReplicas: 1
    containers:
      - name: kserve-container
        image: layout:dev
        imagePullPolicy: Never   # use image built inside Minikube
        ports:
          - containerPort: 8000
            protocol: TCP
        resources:
          requests:
            cpu: "250m"
            memory: "512Mi"
          limits:
            cpu: "2"
            memory: "2Gi"
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 5
